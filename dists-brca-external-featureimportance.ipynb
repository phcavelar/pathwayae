{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import collections\n",
    "import json\n",
    "import itertools\n",
    "import functools\n",
    "import datetime\n",
    "import warnings\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "def get_hex(colour_series:pd.Series):\n",
    "    return colour_series.map(lambda rgb: \"#\" + \"\".join(map(lambda c: hex(int(c*256))[2:], rgb)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "import sklearn.base\n",
    "import sklearn.cluster\n",
    "import umap\n",
    "import lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import skorch\n",
    "import skorch.scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathwayae.models import MLP, Autoencoder, VAE, PAAE, PAVAE, NopLayer\n",
    "from pathwayae.skorch_utils import ScoredNeuralNetAutoencoder\n",
    "\n",
    "from pathwayae.losses import AE_MSELoss, VAELoss, build_beta_schedule\n",
    "\n",
    "from pathwayae.utils import from_log2pk, to_log2pk, fpkm_to_tpm, sample_wise_preprocess_fn, sigmoid, logcurve, logcurve_start_end\n",
    "\n",
    "from pathwayae.pathway_utils import read_pathway_from_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.expanduser(\"~/data/\") \n",
    "tcga_folder = os.path.join(data_folder, \"pathwayae\", \"tcga\")\n",
    "meta_folder = os.path.join(data_folder, \"pathwayae\", \"metabric\")\n",
    "os.makedirs(tcga_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_type = \"BRCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_ensembl_counts_gex_tsv_fname = os.path.join(meta_folder, f\"data_mrna_agilent_microarray.txt.gz\")\n",
    "gex_meta = pd.read_csv(metabric_ensembl_counts_gex_tsv_fname, sep=\"\\t\", index_col=\"Hugo_Symbol\").drop(columns=\"Entrez_Gene_Id\")\n",
    "gex_meta.index.rename(\"SampleID\", inplace=True)\n",
    "gex_meta = gex_meta.T.dropna(axis=\"columns\")\n",
    "gex_meta.columns = gex_meta.columns.str.upper()\n",
    "\n",
    "gex_meta = to_log2pk(fpkm_to_tpm(from_log2pk(gex_meta)))\n",
    "\n",
    "gex_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_meta.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_phenotype_csv_fname = os.path.join(meta_folder, f\"data_clinical_patient.txt.gz\")\n",
    "metabric_phenotype = pd.read_csv(metabric_phenotype_csv_fname, sep=\"\\t\", comment=\"#\", index_col=\"PATIENT_ID\")\n",
    "metabric_phenotype.index.rename(\"SampleID\", inplace=True)\n",
    "metabric_phenotype.rename(columns={\"CLAUDIN_SUBTYPE\": \"PAM50\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_phenotype_csv_fname = os.path.join(meta_folder, f\"data_clinical_patient.txt.gz\")\n",
    "metabric_phenotype = pd.read_csv(metabric_phenotype_csv_fname, sep=\"\\t\", comment=\"#\", index_col=\"PATIENT_ID\")\n",
    "metabric_phenotype.index.rename(\"SampleID\", inplace=True)\n",
    "metabric_phenotype.rename(columns={\"CLAUDIN_SUBTYPE\": \"PAM50\"}, inplace=True)\n",
    "metabric_phenotype = metabric_phenotype[[\"PAM50\",\"OS_MONTHS\",\"OS_STATUS\"]]\n",
    "metabric_phenotype[\"OS_STATUS\"].replace({\"0:LIVING\":0,\"1:DECEASED\":1}, inplace=True)\n",
    "metabric_phenotype.rename(columns={'OS_MONTHS':\"OS_Time\",'OS_STATUS':\"OS_Event\"}, inplace=True)\n",
    "metabric_phenotype[\"OS_Time\"] *= 365/12\n",
    "metabric_phenotype.dropna(subset=[\"PAM50\"], inplace=True)\n",
    "metabric_phenotype.drop(index=metabric_phenotype.index[metabric_phenotype[\"PAM50\"] == \"claudin-low\"], inplace=True)\n",
    "metabric_phenotype.drop(index=metabric_phenotype.index[metabric_phenotype[\"PAM50\"] == \"NC\"], inplace=True)\n",
    "\n",
    "for c in metabric_phenotype.columns:\n",
    "    print(c, metabric_phenotype[c].count(), metabric_phenotype[c].value_counts())\n",
    "\n",
    "metabric_phenotype.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(metabric_phenotype.PAM50.isna())==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_phenotype[\"PAM50\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_fpkm_gex_tsv_fname = os.path.join(tcga_folder, f\"TCGA-{cancer_type}.htseq_fpkm.tsv.gz\")\n",
    "gex = pd.read_csv(ensembl_fpkm_gex_tsv_fname, sep=\"\\t\", index_col=\"Ensembl_ID\").T.dropna(axis=\"columns\")\n",
    "gex = to_log2pk(fpkm_to_tpm(from_log2pk(gex)))\n",
    "\n",
    "zero_variance_columns = set(gex.var()[gex.var()==0].index)\n",
    "\n",
    "gex = gex.drop(columns=list(zero_variance_columns))\n",
    "\n",
    "with open(os.path.join(tcga_folder, \"ensembl_to_gene_id.json\")) as f:\n",
    "    ensembl_to_gex_dict = json.load(f)\n",
    "\n",
    "if True:\n",
    "    columns_to_drop = [k for k in ensembl_to_gex_dict if ensembl_to_gex_dict[k]==\"\" and k not in zero_variance_columns]\n",
    "\n",
    "    gex = gex.drop(columns=columns_to_drop)\n",
    "\n",
    "    \n",
    "gex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    value_counts = {}\n",
    "    for k,v in ensembl_to_gex_dict.items():\n",
    "        if v == '':\n",
    "            continue\n",
    "        elif k in gex.columns:\n",
    "            if v in value_counts:\n",
    "                value_counts[v].append(k)\n",
    "            else:\n",
    "                value_counts[v] = [k]\n",
    "    value_counts = {k:v for k,v in value_counts.items() if len(v)>1}\n",
    "    print(len(value_counts), sum((len(v) for v in value_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_and_in_both = [\"MATR3\", \"EMG1\", \"TMSB15B\", \"BMS1P4\", \"POLR2J4\",]\n",
    "\n",
    "for v in duplicate_and_in_both:\n",
    "    display(gex[value_counts[v]].describe())\n",
    "    display(gex[value_counts[v]].corr())\n",
    "    display(gex_meta[v].describe())\n",
    "\n",
    "[(v,value_counts[v]) for v in duplicate_and_in_both]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values that map to the same gene symbol\n",
    "for g_name, g_ensembl_ids in value_counts.items():\n",
    "    n_ambiguous = len(g_ensembl_ids)\n",
    "    gex[g_name] = to_log2pk(from_log2pk(gex[g_ensembl_ids], 1).mean(axis=1), 1)\n",
    "    gex.drop(columns=g_ensembl_ids, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the rest\n",
    "gex = gex.rename(columns=ensembl_to_gex_dict)\n",
    "\n",
    "gex.columns.rename(\"GeneName\", inplace=True)\n",
    "gex.index.rename(\"SampleID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex.shape, gex_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_in_both = sorted(set(gex_meta.columns).intersection(set(gex.columns)))\n",
    "len(genes_in_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex = gex.loc[:,genes_in_both]\n",
    "gex_meta = gex_meta.loc[:,genes_in_both]\n",
    "gex.shape, gex_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(map(lambda x: x[0]==x[1], list(zip(gex.columns, gex_meta.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_folder = os.path.join(data_folder, \"pathways\")\n",
    "os.makedirs(pathway_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_genes = set(gex.columns.values)\n",
    "gex_genes_indexer = {v:i for i,v in enumerate(gex.columns.values)}\n",
    "get_pathways_with_indices = lambda pathways: [[gex_genes_indexer[gene] for gene in pathway] for pathway in pathways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_pathways = read_pathway_from_json_file(os.path.join(pathway_folder,\"c2.cp.kegg.v7.5.1.json\"), gex_genes)\n",
    "kegg_pathways_with_indices = get_pathways_with_indices(kegg_pathways)\n",
    "number_of_pathways = len(kegg_pathways_with_indices)\n",
    "pathways_input_dimension = sum((len(pathway) for pathway in kegg_pathways_with_indices))\n",
    "number_of_input_genes = len(functools.reduce(lambda acc_p, p: acc_p.union(set(p)), kegg_pathways_with_indices, set()))\n",
    "number_of_pathways, pathways_input_dimension, number_of_input_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark_pathways = read_pathway_from_json_file(os.path.join(pathway_folder,\"h.all.v7.5.1.json\"), gex_genes)\n",
    "hallmark_pathways_with_indices = get_pathways_with_indices(hallmark_pathways)\n",
    "number_of_pathways = len(hallmark_pathways_with_indices)\n",
    "pathways_input_dimension = sum((len(pathway) for pathway in hallmark_pathways_with_indices))\n",
    "number_of_input_genes = len(functools.reduce(lambda acc_p, p: acc_p.union(set(p)), hallmark_pathways_with_indices, set()))\n",
    "number_of_pathways, pathways_input_dimension, number_of_input_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_fpkm_phenotype_tsv_fname = os.path.join(tcga_folder, f\"TCGA.{cancer_type}.sampleMap_{cancer_type}_clinicalMatrix\")\n",
    "phenotype = pd.read_csv(ensembl_fpkm_phenotype_tsv_fname, sep=\"\\t\", index_col=\"sampleID\")\n",
    "phenotype.index = phenotype.index.rename(\"SampleID\")\n",
    "phenotype = phenotype[[c for c in phenotype.columns if \"pam50\" in c.lower()] + ['OS_Time_nature2012', 'OS_event_nature2012',]]\n",
    "phenotype.rename(columns={'OS_Time_nature2012':\"OS_Time\",'OS_event_nature2012':\"OS_Event\"}, inplace=True)\n",
    "for c in phenotype.columns:\n",
    "    print(phenotype[c].count(), phenotype[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_clf_tgt = \"PAM50Call_RNAseq\"\n",
    "phenotype_clf_tgt_meta = \"PAM50\"\n",
    "phenotype_clf_map = {\n",
    "    \"LumA\":0,\n",
    "    \"LumB\":1,\n",
    "    \"Basal\":2,\n",
    "    \"Normal\":3,\n",
    "    \"Her2\":4,\n",
    "}\n",
    "phenotype_clf_nan = {f\"{value}\":np.nan for value in [np.nan, \"not reported\", \"\"]}\n",
    "phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan\n",
    "PHENOTYPE_CLF_COLUMN = \"subtype\"\n",
    "phenotype[PHENOTYPE_CLF_COLUMN] = phenotype[phenotype_clf_tgt].replace(phenotype_clf_nan)\n",
    "phenotype = phenotype.dropna(subset=[PHENOTYPE_CLF_COLUMN])\n",
    "phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_possible_mappings = {idx:[] for idx in phenotype.index}\n",
    "for idx in phenotype.index:\n",
    "    for v in gex[gex.index.str.startswith(idx)].index.values:\n",
    "        _possible_mappings[idx].append(v)\n",
    "_replacements = {k:sorted(v)[0] for k,v in _possible_mappings.items() if len(v)>0}\n",
    "phenotype = phenotype.rename(index=_replacements, inplace=False)\n",
    "phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_index = sorted(set(phenotype.index).intersection(gex.index))\n",
    "[(len(idx), idx[:5],) for idx in [gex.index, phenotype.index, both_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_index_meta = sorted(set(metabric_phenotype.index).intersection(gex_meta.index))\n",
    "[(len(idx), idx[:5],) for idx in [gex_meta.index, metabric_phenotype.index, both_index_meta]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex = gex.loc[both_index]\n",
    "gex_meta = gex_meta.loc[both_index_meta]\n",
    "\n",
    "full_phenotype = phenotype\n",
    "phenotype_meta = full_phenotype_meta = metabric_phenotype\n",
    "\n",
    "phenotype = phenotype.loc[both_index,[PHENOTYPE_CLF_COLUMN,]]\n",
    "phenotype_meta = full_phenotype_meta.loc[both_index_meta,[\"PAM50\"]]\n",
    "phenotype[PHENOTYPE_CLF_COLUMN] = phenotype[PHENOTYPE_CLF_COLUMN].replace(phenotype_clf_map)\n",
    "phenotype_meta[PHENOTYPE_CLF_COLUMN] = phenotype_meta[\"PAM50\"].replace(phenotype_clf_map)\n",
    "phenotype[phenotype_clf_tgt] = full_phenotype.loc[phenotype.index,phenotype_clf_tgt]\n",
    "phenotype_meta[phenotype_clf_tgt_meta] = phenotype_meta.loc[phenotype_meta.index,phenotype_clf_tgt_meta]\n",
    "\n",
    "\n",
    "(\n",
    "    phenotype[PHENOTYPE_CLF_COLUMN].value_counts(), phenotype[PHENOTYPE_CLF_COLUMN].dtype, phenotype[PHENOTYPE_CLF_COLUMN].unique(), phenotype[PHENOTYPE_CLF_COLUMN].describe(),\n",
    "    \"\\n\",\n",
    "    phenotype_meta[PHENOTYPE_CLF_COLUMN].value_counts(), phenotype_meta[PHENOTYPE_CLF_COLUMN].dtype, phenotype_meta[PHENOTYPE_CLF_COLUMN].unique(), phenotype_meta[PHENOTYPE_CLF_COLUMN].describe(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all((gi==pi for gi,pi in zip(gex.index.to_list(), phenotype.index.to_list()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all((gi==pi for gi,pi in zip(gex_meta.index.to_list(), phenotype_meta.index.to_list()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_space(df, SpaceTransformer=sklearn.decomposition.PCA, **kwargs):\n",
    "    values = SpaceTransformer().fit_transform(df)\n",
    "    return sns.scatterplot(x=values[:,0], y=values[:,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_dim = gex.values.shape[1]\n",
    "gex.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_X = sklearn.preprocessing.quantile_transform(gex.values, n_quantiles=max(*gex.values.shape), output_distribution=\"normal\")\n",
    "gex_meta_X = sklearn.preprocessing.quantile_transform(gex_meta.values, n_quantiles=max(*gex_meta.values.shape), output_distribution=\"normal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_p = [torch.tensor(pathway) for pathway in kegg_pathways_with_indices]\n",
    "hmrk_p = [torch.tensor(pathway) for pathway in hallmark_pathways_with_indices]\n",
    "\n",
    "pways_keys_lst = [\"KEGG\", \"Hallmark Genes\",]\n",
    "pways_defs_lst = [kegg_p, hmrk_p,]\n",
    "pways_defs_dict = dict(zip(pways_keys_lst,pways_defs_lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark_pathway_description_path = os.path.join(pathway_folder,\"h.all.v7.5.1.json\")\n",
    "\n",
    "with open(hallmark_pathway_description_path, \"r\") as f:\n",
    "    hallmark_pathway_descriptions = json.load(f)\n",
    "hallmark_pathway_genes = [(k,hallmark_pathway_descriptions[k][\"geneSymbols\"]) for k in hallmark_pathway_descriptions]\n",
    "hallmark_all_pathway_genes = functools.reduce(lambda acc, v: acc.union(set(v[1])), hallmark_pathway_genes, set())\n",
    "hallmark_common_genes = hallmark_all_pathway_genes.intersection(gex_genes)\n",
    "hallmark_pathway_genes_with_allowed_genes = [(k,[gene for gene in pathway if gene in hallmark_common_genes]) for k, pathway in hallmark_pathway_genes]\n",
    "\n",
    "hallmark_pway_names = [k for (k,p), pi in zip(hallmark_pathway_genes_with_allowed_genes,hallmark_pathways_with_indices)]\n",
    "assert(all([(len(p)==len(pi)) for (k,p), pi in zip(hallmark_pathway_genes_with_allowed_genes,hallmark_pathways_with_indices)]))\n",
    "hallmark_pway_names = [pname.replace(\"HALLMARK_\",\"\") for pname in hallmark_pway_names]\n",
    "len(hallmark_pway_names), hallmark_pway_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_pathway_description_path = os.path.join(pathway_folder,\"c2.cp.kegg.v7.5.1.json\")\n",
    "\n",
    "with open(kegg_pathway_description_path, \"r\") as f:\n",
    "    kegg_pathway_descriptions = json.load(f)\n",
    "kegg_pathway_genes = [(k,kegg_pathway_descriptions[k][\"geneSymbols\"]) for k in kegg_pathway_descriptions]\n",
    "kegg_all_pathway_genes = functools.reduce(lambda acc, v: acc.union(set(v[1])), kegg_pathway_genes, set())\n",
    "kegg_common_genes = kegg_all_pathway_genes.intersection(gex_genes)\n",
    "kegg_pathway_genes_with_allowed_genes = [(k,[gene for gene in pathway if gene in kegg_common_genes]) for k, pathway in kegg_pathway_genes]\n",
    "\n",
    "kegg_pway_names = [k for (k,p), pi in zip(kegg_pathway_genes_with_allowed_genes,kegg_pathways_with_indices)]\n",
    "assert(all([(len(p)==len(pi)) for (k,p), pi in zip(kegg_pathway_genes_with_allowed_genes,kegg_pathways_with_indices)]))\n",
    "kegg_pway_names = [pname.replace(\"KEGG_\",\"\") for pname in kegg_pway_names]\n",
    "len(kegg_pway_names), kegg_pway_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_set_to_use = \"KEGG\"\n",
    "base_model_name_to_use = \"PAAE-[32]-[64]\"\n",
    "\n",
    "pathway_set_to_use_dict = {\n",
    "    \"Hallmark Genes\": hallmark_pathway_genes_with_allowed_genes,\n",
    "    \"KEGG\": kegg_pathway_genes_with_allowed_genes,\n",
    "}\n",
    "\n",
    "clustermap_k_map = {\n",
    "    \"KEGG\": 32,\n",
    "    \"Hallmark Genes\": 50\n",
    "}\n",
    "\n",
    "featuremap_k_map = {\n",
    "    \"KEGG\": 32,\n",
    "    \"Hallmark Genes\": 50\n",
    "}\n",
    "\n",
    "violinplot_k_map = {\n",
    "    \"KEGG\": 32,\n",
    "    \"Hallmark Genes\": 50\n",
    "}\n",
    "\n",
    "pways_to_look_at_map = {\n",
    "    \"KEGG\": [\"KEGG_GLYCOSAMINOGLYCAN_BIOSYNTHESIS_KERATAN_SULFATE\", \"KEGG_SPHINGOLIPID_METABOLISM\", \"KEGG_VALINE_LEUCINE_AND_ISOLEUCINE_DEGRADATION\", \"KEGG_P53_SIGNALING_PATHWAY\", \"KEGG_PANCREATIC_CANCER\", \"KEGG_GLIOMA\", \"KEGG_MISMATCH_REPAIR\"],\n",
    "    \"Hallmark Genes\": [\"HALLMARK_P53_PATHWAY\", \"HALLMARK_UV_RESPONSE_DN\", \"HALLMARK_CHOLESTEROL_HOMEOSTASIS\", \"HALLMARK_APICAL_SURFACE\", \"HALLMARK_MTORC1_SIGNALING\"]\n",
    "}\n",
    "\n",
    "pway_names_and_genes = pathway_set_to_use_dict[pathway_set_to_use]\n",
    "pways_to_look_at = pways_to_look_at_map[pathway_set_to_use]\n",
    "base_model_name = f\"{base_model_name_to_use} ({pathway_set_to_use})\"\n",
    "base_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = base_model_name\n",
    "model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "pathway_hidden_dims = list(map(int, re.findall(\"\\[(.*?)\\]\", model_name)[0].split(\",\")))\n",
    "hidden_and_enc_dims = list(map(int, re.findall(\"\\[(.*?)\\]\", model_name)[1].split(\",\")))\n",
    "model_fname, hidden_and_enc_dims, pathway_hidden_dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/metabric\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "images_folder = \"images/metabric\"\n",
    "os.makedirs(images_folder, exist_ok=True)\n",
    "SAVING_FORMATS = [\"png\", \"pdf\", \"svg\"]\n",
    "for fmt in SAVING_FORMATS: os.makedirs(os.path.join(images_folder,fmt), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"PAVAE\" in model_name:\n",
    "    ModelClass = PAVAE\n",
    "    model_kwargs = {\n",
    "        \"genes_dim\": genes_dim,\n",
    "        \"pathway_definitions\": pways_defs_dict[pathway_set_to_use],\n",
    "        \"pathway_hidden_dims\": pathway_hidden_dims,\n",
    "        \"hidden_dims\": hidden_and_enc_dims[:-1],\n",
    "        \"encoding_dim\": hidden_and_enc_dims[-1],\n",
    "    }\n",
    "elif \"PAAE\" in model_name:\n",
    "    ModelClass = PAAE\n",
    "    genes_dim = gex_X.shape[1]\n",
    "    model_kwargs = {\n",
    "        \"genes_dim\": genes_dim,\n",
    "        \"pathway_definitions\": pways_defs_dict[pathway_set_to_use],\n",
    "        \"pathway_hidden_dims\": pathway_hidden_dims,\n",
    "        \"hidden_dims\": hidden_and_enc_dims[:-1],\n",
    "        \"encoding_dim\": hidden_and_enc_dims[-1],\n",
    "    }\n",
    "else:\n",
    "    raise ValueError(f\"{model_name} does not exist\")\n",
    "\n",
    "model = ModelClass(**model_kwargs)\n",
    "model.load_state_dict(torch.load(os.path.join(results_folder,f\"{model_fname}.pt\")))\n",
    "model.eval()\n",
    "\n",
    "gex_a = model.get_pathway_activities(torch.tensor(gex_X, dtype=torch.float32)).detach().numpy()\n",
    "gex_meta_a = model.get_pathway_activities(torch.tensor(gex_meta_X, dtype=torch.float32)).detach().numpy()\n",
    "\n",
    "if \"PAVAE\" in model_name:\n",
    "    gex_z = model.encode(torch.tensor(gex_X, dtype=torch.float32))[0].detach().numpy()\n",
    "    gex_meta_z = model.encode(torch.tensor(gex_meta_X, dtype=torch.float32))[0].detach().numpy()\n",
    "elif \"PAAE\" in model_name:\n",
    "    gex_z = model(torch.tensor(gex_X, dtype=torch.float32))[0].detach().numpy()\n",
    "    gex_meta_z = model(torch.tensor(gex_meta_X, dtype=torch.float32))[0].detach().numpy()\n",
    "else:\n",
    "    raise ValueError(f\"{model_name} does not exist\")\n",
    "\n",
    "len(model.pathway_encoders), gex_a.shape, gex_z.shape, gex_meta_a.shape, gex_meta_z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_simple_feature_importance(E:MLP) -> np.ndarray:\n",
    "    return functools.reduce(\n",
    "        (lambda acc, l: l.weight.detach().numpy() @ acc),\n",
    "        E.layers[1:],\n",
    "        E.layers[0].weight.detach().numpy()\n",
    "    ).squeeze()\n",
    "\n",
    "def get_simple_abs_feature_importance(E:MLP) -> np.ndarray:\n",
    "    return functools.reduce(\n",
    "        (lambda acc, l: np.abs(l.weight.detach().numpy()) @ acc),\n",
    "        E.layers[1:],\n",
    "        np.abs(E.layers[0].weight.detach().numpy())\n",
    "    ).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_importances = list(zip(pway_names_and_genes,map(get_simple_feature_importance, model.pathway_encoders)))\n",
    "pathways = [p for (p,g),i in pathway_importances]\n",
    "genes = sorted(functools.reduce(lambda acc, genes: acc.union(genes), [g for (p,g),i in pathway_importances], set()))\n",
    "gene_to_idx_map = dict(zip(genes, range(len(genes))))\n",
    "\n",
    "feature_importance_matrix = np.full((len(pathway_importances), len(genes)), np.nan)\n",
    "\n",
    "for pwy_idx, ((pwy,gen),imp) in enumerate(pathway_importances):\n",
    "    gen_idxs = [gene_to_idx_map[g] for g in gen]\n",
    "    feature_importance_matrix[pwy_idx, gen_idxs] = imp\n",
    "\n",
    "pathway_feature_importance_df = pd.DataFrame(data=feature_importance_matrix, columns=genes, index=pathways)\n",
    "pathway_feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_importances = list(zip(pway_names_and_genes,map(get_simple_abs_feature_importance, model.pathway_encoders)))\n",
    "pathways = [p for (p,g),i in pathway_importances]\n",
    "genes = sorted(functools.reduce(lambda acc, genes: acc.union(genes), [g for (p,g),i in pathway_importances], set()))\n",
    "gene_to_idx_map = dict(zip(genes, range(len(genes))))\n",
    "\n",
    "feature_importance_matrix = np.full((len(pathway_importances), len(genes)), np.nan)\n",
    "\n",
    "for pwy_idx, ((pwy,gen),imp) in enumerate(pathway_importances):\n",
    "    gen_idxs = [gene_to_idx_map[g] for g in gen]\n",
    "    feature_importance_matrix[pwy_idx, gen_idxs] = imp\n",
    "\n",
    "pathway_feature_importance_abs_df = pd.DataFrame(data=feature_importance_matrix, columns=genes, index=pathways)\n",
    "pathway_feature_importance_abs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp_k_max = 20\n",
    "imp_k_range = list(range(2, imp_k_max+1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    print(\"\\\\multirow{2}{*}{\"+pway_name.replace(\"HALLMARK_\",\"\").replace(\"KEGG_\",\"\").replace(\"_\",\"\\\\_\")+\"}\")\n",
    "    print(\"\", *most_important_anpw.index, sep=\" & \", end=\" \\\\\\\\\\n\")\n",
    "    print(\"\", *map(lambda x: f\"{x:+.2f}\", most_important_anpw.values), sep=\" & \", end=\" \\\\\\\\\\n\")\n",
    "    print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pam_50_genes = [\"FOXC1\", \"MIA\", \"KNTC2\", \"CEP55\", \"ANLN\", \"MELK\", \"GPR160\", \"TMEM45B\", \"ESR1\", \"FOXA1\", \"ERBB2\", \"GRB7\", \"FGFR4\", \"BLVRA\", \"BAG1\", \"CDC20\", \"CCNE1\", \"ACTR3B\", \"MYC\", \"SFRP1\", \"KRT14\", \"KRT17\", \"KRT5\", \"MLPH\", \"CCNB1\", \"CDC6\", \"TYMS\", \"UBE2T\", \"RRM2\", \"MMP11\", \"CXXC5\", \"ORC6L\", \"MDM2\", \"KIF2C\", \"PGR\", \"MKI67\", \"BCL2\", \"EGFR\", \"PHGDH\", \"CDH3\", \"NAT1\", \"SLC39A6\", \"MAPT\", \"UBE2C\", \"PTTG1\", \"EXO1\", \"CENPF\", \"CDCA1\", \"MYBL2\", \"BIRC5\"]\n",
    "len(list(filter(lambda x: x in pathway_feature_importance_df.columns, pam_50_genes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    print(pway_name)\n",
    "    print(*filter(lambda x: x in pam_50_genes, most_important_anpw.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log10(0.0501187)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    p_values_tcga = [\n",
    "        lifelines.CoxPHFitter().fit(gex.loc[:,[feat]].join(full_phenotype[[\"OS_Time\", \"OS_Event\"]]).dropna(), duration_col=\"OS_Time\", event_col=\"OS_Event\").summary.loc[feat,\"p\"]\n",
    "        for feat in most_important_anpw.index\n",
    "    ]\n",
    "    p_values_meta = [\n",
    "        lifelines.CoxPHFitter().fit(gex_meta.loc[:,[feat]].join(full_phenotype_meta[[\"OS_Time\", \"OS_Event\"]]).dropna(), duration_col=\"OS_Time\", event_col=\"OS_Event\").summary.loc[feat,\"p\"]\n",
    "        for feat in most_important_anpw.index\n",
    "    ]\n",
    "    all = list(zip(most_important_anpw.index, p_values_tcga, p_values_meta))\n",
    "    significant_both = list(filter((lambda x: x[1]<=0.05 and x[2]<=0.05), all))\n",
    "    significant_any = list(filter((lambda x: x[1]<=0.05 or x[2]<=0.05), all))\n",
    "    significant_tcga = list(filter((lambda x: x[1]<=0.05), all))\n",
    "    significant_meta = list(filter((lambda x: x[2]<=0.05), all))\n",
    "    print(pway_name, *map(lambda x: len(x)/len(most_important_anpw.index), [significant_both, significant_any, significant_tcga, significant_meta]))\n",
    "    print(*map(lambda x: f\"{x[0]} {np.log10(x[1]):.1f} {np.log10(x[2]):.1f}\", all))\n",
    "    print(*map(lambda x: x[0], significant_both))\n",
    "    print(*map(lambda x: x[0], significant_tcga))\n",
    "    print(*map(lambda x: x[0], significant_meta))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(ascending=False)\n",
    "    sns.barplot(x=most_important_anpw.values, y=most_important_anpw.index, hue=[(\"+\" if b else \"-\") for b in (most_important_anpw.values>0)], dodge=False)\n",
    "    plt.xlabel(\"Neural Path Weight\")\n",
    "    plt.legend([],[])\n",
    "    plt.title(pway_name)\n",
    "    for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"importantfeatures_mostimportant_{model_fname}_{pway_name}.{fmt}\"), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    pathway_feature_importance_df.loc[pway_name].dropna().hist()\n",
    "    plt.xlabel(\"Neural Path Weight\")\n",
    "    for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"importantfeatures_weightdist_{model_fname}_{pway_name}.{fmt}\"), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    print(\"\\\\multirow{2}{*}{\"+pway_name.replace(\"HALLMARK_\",\"\").replace(\"KEGG_\",\"\").replace(\"_\",\"\\\\_\")+\"}\")\n",
    "    print(\"\", *most_important_anpw.index, sep=\" & \", end=\" \\\\\\\\\\n\")\n",
    "    print(\"\", *map(lambda x: f\"{x:+.6f}\", most_important_anpw.values), sep=\" & \", end=\" \\\\\\\\\\n\")\n",
    "    print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a categorical palette to identify the networks\n",
    "unique_phenotypes = phenotype[phenotype_clf_tgt].unique()\n",
    "\n",
    "phenotype_pal = sns.color_palette(n_colors=len(unique_phenotypes))\n",
    "phenotype_lut = dict(zip(unique_phenotypes, phenotype_pal))\n",
    "\n",
    "# Create a categorical palette to identify the networks\n",
    "unique_pways = [p for p in pways_to_look_at]\n",
    "\n",
    "pway_pal = sns.palettes.color_palette(sns.color_palette(n_colors=len(unique_pways)+len(unique_phenotypes))[len(unique_phenotypes):])\n",
    "pway_lut = dict(zip(unique_pways, pway_pal))\n",
    "\n",
    "display(phenotype_pal)\n",
    "display(pway_pal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_in_all_pathways_src_pathway = []\n",
    "genes_in_all_pathways = []\n",
    "\n",
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    genes_in_all_pathways_src_pathway.extend([pway_name]*len(most_important_anpw.index))\n",
    "    genes_in_all_pathways.extend(most_important_anpw.index)\n",
    "\n",
    "    for gex_df, pheno_series, dset_label in [[gex, phenotype[phenotype_clf_tgt], \"TCGA\"], [gex_meta, phenotype_meta[phenotype_clf_tgt_meta], \"Metabric\"]]:\n",
    "        phenotype_colors = pd.Series(pheno_series, name=\"PAM50\").map(phenotype_lut)\n",
    "\n",
    "        plot_df = gex_df.loc[:,most_important_anpw.index]\n",
    "\n",
    "        g = sns.clustermap(plot_df.T, \n",
    "                        col_colors=phenotype_colors,\n",
    "                        col_cluster=True,\n",
    "                        row_cluster=False,\n",
    "                        cmap=\"vlag\",\n",
    "                        cbar_pos=(0.1, .2, .03, .4),\n",
    "        )\n",
    "        old_yticks = g.ax_heatmap.get_yticks()\n",
    "        new_yticks = np.arange(min(old_yticks),min(old_yticks)+len(plot_df.columns),1)\n",
    "        g.ax_col_colors.set_title(pway_name)\n",
    "        g.ax_heatmap.set_xticklabels([])\n",
    "        g.ax_heatmap.set_xlabel(dset_label)\n",
    "        handles = [Patch(facecolor=phenotype_lut[name]) for name in phenotype_lut]\n",
    "        g.ax_row_dendrogram.remove()\n",
    "        g.ax_col_dendrogram.remove()\n",
    "        plt.legend(\n",
    "            handles,\n",
    "            phenotype_lut,\n",
    "            title='PAM50',\n",
    "            bbox_to_anchor=(0.2, 0.7),\n",
    "            bbox_transform=plt.gcf().transFigure,\n",
    "            loc='right')\n",
    "        for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"importantfeatures_heatmap_{model_fname}_{pway_name}_{dset_label}.{fmt}\"), bbox_inches=\"tight\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit to 50 biggest\n",
    "plot_genes_in_all_pathways_src_pathway = genes_in_all_pathways_src_pathway[:50]\n",
    "plot_genes_in_all_pathways = genes_in_all_pathways[:50]\n",
    "\n",
    "for gex_df, pheno_series, dset_label in [[gex, phenotype[phenotype_clf_tgt], \"TCGA\"], [gex_meta, phenotype_meta[phenotype_clf_tgt_meta], \"Metabric\"]]:\n",
    "    phenotype_colors = pd.Series(pheno_series, name=\"PAM50\").map(phenotype_lut)\n",
    "    pway_colors = pd.Series(plot_genes_in_all_pathways_src_pathway, index=plot_genes_in_all_pathways, name=\"Pway\").map(pway_lut)\n",
    "\n",
    "    plot_df:pd.DataFrame = gex_df.loc[:,plot_genes_in_all_pathways]\n",
    "\n",
    "    g = sns.clustermap(plot_df.T, \n",
    "                    col_colors=phenotype_colors,\n",
    "                    col_cluster=True,\n",
    "                    row_colors=pway_colors,\n",
    "                    row_cluster=True,\n",
    "                    cmap=\"vlag\",\n",
    "                    cbar_pos=(0.1, .2, .03, .4),\n",
    "    )\n",
    "    old_yticks = g.ax_heatmap.get_yticks()\n",
    "    old_yticklabels = g.ax_heatmap.get_yticklabels()\n",
    "    new_yticks = np.arange(min(old_yticks),min(old_yticks)+len(plot_df.columns),1)\n",
    "    g.ax_heatmap.set_yticks(new_yticks, labels = plot_df.columns[g.dendrogram_row.reordered_ind])\n",
    "    g.ax_heatmap.set_xticklabels([])\n",
    "    g.ax_heatmap.set_xlabel(dset_label)\n",
    "    g.ax_row_dendrogram.remove()\n",
    "    phenotype_handles = [Patch(facecolor=phenotype_lut[name]) for name in phenotype_lut]\n",
    "    plt.legend(\n",
    "        phenotype_handles,\n",
    "        phenotype_lut,\n",
    "        title='PAM50',\n",
    "        bbox_to_anchor=(0.2, 0.7),\n",
    "        bbox_transform=plt.gcf().transFigure,\n",
    "        loc='right')\n",
    "    for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"importantfeatures_heatmap_{model_fname}_5pways_{dset_label}.{fmt}\"), bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    print(\"\\\\multirow{2}{*}{\"+pway_name.replace(\"HALLMARK_\",\"\").replace(\"KEGG_\",\"\").replace(\"_\",\"\\\\_\")+\"}\")\n",
    "    print(\"\", *most_important_anpw.index, sep=\" & \", end=\" \\\\\\\\\\n\")\n",
    "    print(\"\", *map(lambda x: f\"{x:+.2f}\", most_important_anpw.values), sep=\" & \", end=\" \\\\\\\\\\n\")\n",
    "    print(\"\\\\midrule\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters = 3\n",
    "only_min_max = True\n",
    "use_quantiles = True\n",
    "q_values = [i/n_clusters for i in range(n_clusters+1)]\n",
    "time_limit = 365*5\n",
    "\n",
    "\n",
    "p_values_dict = {\n",
    "    \"feat\": [],\n",
    "    \"feat_idx\": [],\n",
    "    \"pway\": [],\n",
    "    \"tcga-coxph\": [],\n",
    "    \"tcga-logrank\": [],\n",
    "    \"survf-t\": [],\n",
    "    \"tcga-survf-lo\": [],\n",
    "    \"tcga-survf-hi\": [],\n",
    "    \"meta-coxph\": [],\n",
    "    \"meta-logrank\": [],\n",
    "    \"meta-survf-lo\": [],\n",
    "    \"meta-survf-hi\": [],\n",
    "}\n",
    "\n",
    "for pway_name in pways_to_look_at:\n",
    "    imp_k = max(imp_k_range)\n",
    "    most_strong_noabs = abs(pathway_feature_importance_df.loc[pway_name].dropna()).sort_values()[-imp_k//2:]\n",
    "    most_important_anpw = pathway_feature_importance_df.loc[pway_name,most_strong_noabs.index].sort_values(key=lambda x:np.abs(x), ascending=False)\n",
    "    p_values_tcga = [\n",
    "        lifelines.CoxPHFitter().fit(gex.loc[:,[feat]].join(full_phenotype[[\"OS_Time\", \"OS_Event\"]]).dropna(), duration_col=\"OS_Time\", event_col=\"OS_Event\").summary.loc[feat,\"p\"]\n",
    "        for feat in most_important_anpw.index\n",
    "    ]\n",
    "    p_values_meta = [\n",
    "        lifelines.CoxPHFitter().fit(gex_meta.loc[:,[feat]].join(full_phenotype_meta[[\"OS_Time\", \"OS_Event\"]]).dropna(), duration_col=\"OS_Time\", event_col=\"OS_Event\").summary.loc[feat,\"p\"]\n",
    "        for feat in most_important_anpw.index\n",
    "    ]\n",
    "    all = list(zip(most_important_anpw.index, p_values_tcga, p_values_meta))\n",
    "\n",
    "    for feat_idx, (feat, p_tcga, p_meta) in enumerate(all):\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2, sharex=True, sharey=True)\n",
    "        kmfs_dict = {}\n",
    "        for ax_idx, (gex_df, pheno_df, label) in enumerate([[gex, full_phenotype, \"TCGA\"], [gex_meta, full_phenotype_meta, \"Metabric\"]]):\n",
    "            if use_quantiles:\n",
    "                quantiles = [gex_df.loc[:,feat].quantile(q=q) for q in q_values]\n",
    "                cluster_values = np.argmax(\n",
    "                    np.stack(\n",
    "                        [\n",
    "                            np.logical_and(\n",
    "                                q_low<=gex_df.loc[:,feat],\n",
    "                                gex_df.loc[:,feat]<q_high\n",
    "                            )\n",
    "                            for q_low, q_high in zip(quantiles[:-1],quantiles[1:])\n",
    "                        ],\n",
    "                        axis=1\n",
    "                    ),\n",
    "                    axis=1,\n",
    "                )\n",
    "            else:\n",
    "                kmeans = sklearn.cluster.KMeans(n_clusters).fit(gex_df.loc[:,[feat]])\n",
    "                cluster_values = kmeans.predict(gex_df.loc[:,[feat]])\n",
    "                cluster_values = np.argsort(kmeans.cluster_centers_.flatten())[cluster_values]\n",
    "            # Logrank test\n",
    "            logrank_pheno_df = pheno_df.loc[gex_df.index,[\"OS_Time\",\"OS_Event\"]]\n",
    "            logrank_cluster_indexing = (\n",
    "                np.logical_or(cluster_values==0,cluster_values==n_clusters-1)\n",
    "                    if only_min_max else\n",
    "                np.ones_like(cluster_values, dtype=bool)\n",
    "            )\n",
    "            logrank_p_result = lifelines.statistics.multivariate_logrank_test(\n",
    "                event_durations = logrank_pheno_df.loc[np.logical_or(cluster_values==0,cluster_values==n_clusters-1),\"OS_Time\"],\n",
    "                event_observed = logrank_pheno_df.loc[np.logical_or(cluster_values==0,cluster_values==n_clusters-1),\"OS_Event\"],\n",
    "                groups = cluster_values[np.logical_or(cluster_values==0,cluster_values==n_clusters-1)],\n",
    "                t_0 = time_limit,\n",
    "            )\n",
    "            # Cluster labels\n",
    "            cluster_labels = list(range(n_clusters))\n",
    "            if n_clusters == 2:\n",
    "                cluster_labels = [\"low\", \"high\"]\n",
    "            elif n_clusters == 3:\n",
    "                cluster_labels = [\"low\", \"medium\", \"high\"]\n",
    "            elif n_clusters == 4:\n",
    "                cluster_labels = [\"low\", \"medium-low\", \"medium-high\", \"high\"]\n",
    "            for i in ([0,n_clusters-1] if only_min_max else range(n_clusters)):\n",
    "                cluster_idx = gex_df.index[cluster_values==i]\n",
    "                plot_pheno = pheno_df.loc[cluster_idx,[\"OS_Time\",\"OS_Event\"]].dropna()\n",
    "                kmf = lifelines.KaplanMeierFitter().fit(\n",
    "                    plot_pheno[\"OS_Time\"],\n",
    "                    plot_pheno[\"OS_Event\"],\n",
    "                    label = cluster_labels[i],\n",
    "                )\n",
    "                kmfs_dict[(label,i)] = kmf\n",
    "                kmf.plot(loc=slice(0,time_limit if time_limit>=0 else plot_pheno[\"OS_Time\"].max()), ax=axes[ax_idx])\n",
    "            axes[ax_idx].set_title(f\"{label}\" + \" ($\\\\log_{10} p = \" + f\"{np.log10(logrank_p_result.p_value):.1f}$)\")\n",
    "            if label == \"TCGA\":    \n",
    "                p_values_dict[\"tcga-logrank\"].append(logrank_p_result.p_value)\n",
    "            else:\n",
    "                p_values_dict[\"meta-logrank\"].append(logrank_p_result.p_value)\n",
    "        p_values_dict[\"tcga-coxph\"].append(p_tcga)\n",
    "        p_values_dict[\"meta-coxph\"].append(p_meta)\n",
    "        smallest_last_surv_time = min(\n",
    "            time_limit,\n",
    "            *map(\n",
    "                max,\n",
    "                [\n",
    "                    kmfs_dict[(\"TCGA\",0)].survival_function_.index,\n",
    "                    kmfs_dict[(\"Metabric\",0)].survival_function_.index,\n",
    "                    *( [] if only_min_max else [\n",
    "                        kmfs_dict[(\"TCGA\",i)].survival_function_.index for i in range(1,n_clusters-2)\n",
    "                    ]),\n",
    "                    *( [] if only_min_max else [\n",
    "                        kmfs_dict[(\"Metabric\",i)].survival_function_.index for i in range(1,n_clusters-2)\n",
    "                    ]),\n",
    "                    kmfs_dict[(\"TCGA\",n_clusters-1)].survival_function_.index,\n",
    "                    kmfs_dict[(\"Metabric\",n_clusters-1)].survival_function_.index,\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "        p_values_dict[\"survf-t\"].append(smallest_last_surv_time)\n",
    "        p_values_dict[\"tcga-survf-lo\"].append(kmfs_dict[(\"TCGA\",0)].predict(smallest_last_surv_time))\n",
    "        p_values_dict[\"tcga-survf-hi\"].append(kmfs_dict[(\"TCGA\",n_clusters-1)].predict(smallest_last_surv_time))\n",
    "        p_values_dict[\"meta-survf-lo\"].append(kmfs_dict[(\"Metabric\",0)].predict(smallest_last_surv_time))\n",
    "        p_values_dict[\"meta-survf-hi\"].append(kmfs_dict[(\"Metabric\",n_clusters-1)].predict(smallest_last_surv_time))\n",
    "        p_values_dict[\"feat\"].append(feat)\n",
    "        p_values_dict[\"feat_idx\"].append(feat_idx)\n",
    "        p_values_dict[\"pway\"].append(pway_name)\n",
    "        fig.tight_layout()\n",
    "        fig.suptitle(\n",
    "            f\"{pway_name} - {feat}\"\n",
    "        )\n",
    "        fig.tight_layout()\n",
    "        for fmt in SAVING_FORMATS: fig.savefig(os.path.join(images_folder,fmt,f\"kaplanmeier_{model_fname}_{pway_name}_{feat}.{fmt}\"), bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df = pd.DataFrame(p_values_dict)\n",
    "\n",
    "p_values_df = p_values_df.loc[p_values_df[\"pway\"].apply(lambda p: p in pways_to_look_at[:5])]\n",
    "\n",
    "p_values_df[\"tcga-logrank-significant\"] = p_values_df[\"tcga-logrank\"]<0.05\n",
    "p_values_df = p_values_df.loc[p_values_df[\"tcga-logrank-significant\"]]\n",
    "p_values_df[\"meta-logrank-significant\"] = p_values_df[\"meta-logrank\"]<0.05\n",
    "\n",
    "p_values_df[\"both-logrank-significant\"] = np.logical_and(p_values_df[\"tcga-logrank-significant\"], p_values_df[\"meta-logrank-significant\"])\n",
    "\n",
    "p_values_df[\"tcga-survf-a\"] = p_values_df[\"tcga-survf-hi\"]-p_values_df[\"tcga-survf-lo\"]\n",
    "p_values_df[\"meta-survf-a\"] = p_values_df[\"meta-survf-hi\"]-p_values_df[\"meta-survf-lo\"]\n",
    "\n",
    "p_values_df[\"survf-match\"] = np.sign(p_values_df[\"tcga-survf-a\"])==np.sign(p_values_df[\"meta-survf-a\"])\n",
    "\n",
    "p_values_df[\"both-logrank-significant-and-survf-match\"] = np.logical_and(p_values_df[\"both-logrank-significant\"],p_values_df[\"survf-match\"])\n",
    "p_values_df.sort_values(by=[\"both-logrank-significant\", \"feat\"], axis=\"index\", ascending=[False,True], inplace=True)\n",
    "print(model_fname)\n",
    "print(p_values_df[\"both-logrank-significant-and-survf-match\"].mean())\n",
    "print(p_values_df[\"both-logrank-significant-and-survf-match\"].describe())\n",
    "display(p_values_df[[\"feat\",\"pway\",\"both-logrank-significant-and-survf-match\",\"both-logrank-significant\",\"survf-match\",\"tcga-logrank\",\"meta-logrank\",\"survf-t\",\"tcga-survf-lo\",\"tcga-survf-hi\",\"meta-survf-lo\",\"meta-survf-hi\",]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_values_df[[\"feat\",\"pway\",\"tcga-logrank\",\"meta-logrank\"]].set_index([\"feat\",\"pway\"]).apply(np.log10).round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6aa1c49e068f69db5bcdfd06143621343d5e21d0aa95c73e4e0dd023b1fedc27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
