{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import time\n",
    "import collections\n",
    "import json\n",
    "import itertools\n",
    "import functools\n",
    "import datetime\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.model_selection\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "import sklearn.feature_selection\n",
    "import sklearn.metrics\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sklearn.linear_model\n",
    "import sklearn.svm\n",
    "import sklearn.ensemble\n",
    "import sklearn.base\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import skorch\n",
    "import skorch.scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathwayae.models import MLP, Autoencoder, VAE, PAAE, PAVAE, PACAE, NopLayer\n",
    "from pathwayae.skorch_utils import ScoredNeuralNetAutoencoder\n",
    "\n",
    "from pathwayae.losses import AE_MSELoss, VAELoss, build_beta_schedule\n",
    "\n",
    "from pathwayae.utils import from_log2pk, to_log2pk, fpkm_to_tpm, sample_wise_preprocess_fn, sigmoid, logcurve, logcurve_start_end\n",
    "\n",
    "from pathwayae.pathway_utils import read_pathway_from_json_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = os.path.expanduser(\"~/data/\") \n",
    "tcga_folder = os.path.join(data_folder, \"pathwayae\", \"tcga\")\n",
    "meta_folder = os.path.join(data_folder, \"pathwayae\", \"metabric\")\n",
    "os.makedirs(tcga_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer_type = \"BRCA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_ensembl_counts_gex_tsv_fname = os.path.join(meta_folder, f\"data_mrna_agilent_microarray.txt.gz\")\n",
    "gex_meta = pd.read_csv(metabric_ensembl_counts_gex_tsv_fname, sep=\"\\t\", index_col=\"Hugo_Symbol\").drop(columns=\"Entrez_Gene_Id\")\n",
    "gex_meta.index.rename(\"SampleID\", inplace=True)\n",
    "gex_meta = gex_meta.T.dropna(axis=\"columns\")\n",
    "gex_meta.columns = gex_meta.columns.str.upper()\n",
    "\n",
    "gex_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_meta.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_phenotype_csv_fname = os.path.join(meta_folder, f\"data_clinical_patient.txt.gz\")\n",
    "metabric_phenotype = pd.read_csv(metabric_phenotype_csv_fname, sep=\"\\t\", comment=\"#\", index_col=\"PATIENT_ID\")\n",
    "metabric_phenotype.index.rename(\"SampleID\", inplace=True)\n",
    "metabric_phenotype.rename(columns={\"CLAUDIN_SUBTYPE\": \"PAM50\"}, inplace=True)\n",
    "metabric_phenotype = metabric_phenotype[[\"PAM50\"]]\n",
    "metabric_phenotype.dropna(inplace=True)\n",
    "metabric_phenotype.drop(index=metabric_phenotype.index[metabric_phenotype[\"PAM50\"] == \"claudin-low\"], inplace=True)\n",
    "metabric_phenotype.drop(index=metabric_phenotype.index[metabric_phenotype[\"PAM50\"] == \"NC\"], inplace=True)\n",
    "\n",
    "for c in metabric_phenotype.columns:\n",
    "    print(c, metabric_phenotype[c].count(), metabric_phenotype[c].value_counts())\n",
    "\n",
    "metabric_phenotype.index[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(metabric_phenotype.PAM50.isna())==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metabric_phenotype[\"PAM50\"].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_fpkm_gex_tsv_fname = os.path.join(tcga_folder, f\"TCGA-{cancer_type}.htseq_fpkm.tsv.gz\")\n",
    "gex = pd.read_csv(ensembl_fpkm_gex_tsv_fname, sep=\"\\t\", index_col=\"Ensembl_ID\").T.dropna(axis=\"columns\")\n",
    "\n",
    "zero_variance_columns = set(gex.var()[gex.var()==0].index)\n",
    "\n",
    "gex = gex.drop(columns=list(zero_variance_columns))\n",
    "\n",
    "with open(os.path.join(tcga_folder, \"ensembl_to_gene_id.json\")) as f:\n",
    "    ensembl_to_gex_dict = json.load(f)\n",
    "\n",
    "if True:\n",
    "    columns_to_drop = [k for k in ensembl_to_gex_dict if ensembl_to_gex_dict[k]==\"\" and k not in zero_variance_columns]\n",
    "\n",
    "    gex = gex.drop(columns=columns_to_drop)\n",
    "\n",
    "    \n",
    "gex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    value_counts = {}\n",
    "    for k,v in ensembl_to_gex_dict.items():\n",
    "        if v == '':\n",
    "            continue\n",
    "        elif k in gex.columns:\n",
    "            if v in value_counts:\n",
    "                value_counts[v].append(k)\n",
    "            else:\n",
    "                value_counts[v] = [k]\n",
    "    value_counts = {k:v for k,v in value_counts.items() if len(v)>1}\n",
    "    print(len(value_counts), sum((len(v) for v in value_counts.values())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_and_in_both = [\"MATR3\", \"EMG1\", \"TMSB15B\", \"BMS1P4\", \"POLR2J4\",]\n",
    "\n",
    "for v in duplicate_and_in_both:\n",
    "    display(gex[value_counts[v]].describe())\n",
    "    display(gex[value_counts[v]].corr())\n",
    "    display(gex_meta[v].describe())\n",
    "\n",
    "[(v,value_counts[v]) for v in duplicate_and_in_both]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for g_name, g_ensembl_ids in [(v,value_counts[v]) for v in duplicate_and_in_both]:\n",
    "    n_ambiguous = len(g_ensembl_ids)\n",
    "    fig, axes = plt.subplots(3+n_ambiguous,1, sharex=True, sharey=True, figsize=[plt.rcParams[\"figure.figsize\"][0], plt.rcParams[\"figure.figsize\"][1]*1.5])\n",
    "    to_log2pk(from_log2pk(gex[g_ensembl_ids], 1).sum(axis=1), 1).hist(bins=20, ax=axes[n_ambiguous])\n",
    "    axes[n_ambiguous].set_title(f\"sum {g_name} (tcga, fpkm)\")\n",
    "    to_log2pk(from_log2pk(gex[g_ensembl_ids], 1).mean(axis=1), 1).hist(bins=20, ax=axes[n_ambiguous+1])\n",
    "    axes[n_ambiguous+1].set_title(f\"mean {g_name} (tcga, fpkm)\")\n",
    "    gex_meta[g_name].hist(bins=20, ax=axes[n_ambiguous+2])\n",
    "    axes[n_ambiguous+2].set_title(f\"{g_name} (metabric, counts)\")\n",
    "    for i, g_e_idx in enumerate(g_ensembl_ids):\n",
    "        gex[g_e_idx].hist(bins=20, ax=axes[i])\n",
    "        axes[i].set_title(f\"{g_e_idx} (tcga, fpkm)\")\n",
    "    axes[n_ambiguous+2].set_xlabel(\"log2p1\")\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge values that map to the same gene symbol\n",
    "for g_name, g_ensembl_ids in value_counts.items():\n",
    "    n_ambiguous = len(g_ensembl_ids)\n",
    "    gex[g_name] = to_log2pk(from_log2pk(gex[g_ensembl_ids], 1).mean(axis=1), 1)\n",
    "    gex.drop(columns=g_ensembl_ids, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the rest\n",
    "gex = gex.rename(columns=ensembl_to_gex_dict)\n",
    "\n",
    "gex.columns.rename(\"GeneName\", inplace=True)\n",
    "gex.index.rename(\"SampleID\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex.shape, gex_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_in_both = sorted(set(gex_meta.columns).intersection(set(gex.columns)))\n",
    "len(genes_in_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex = gex.loc[:,genes_in_both]\n",
    "gex_meta = gex_meta.loc[:,genes_in_both]\n",
    "gex.shape, gex_meta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert all(map(lambda x: x[0]==x[1], list(zip(gex.columns, gex_meta.columns))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_folder = os.path.join(data_folder, \"pathways\")\n",
    "os.makedirs(pathway_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex_genes = set(gex.columns.values)\n",
    "gex_genes_indexer = {v:i for i,v in enumerate(gex.columns.values)}\n",
    "get_pathways_with_indices = lambda pathways: [[gex_genes_indexer[gene] for gene in pathway] for pathway in pathways]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_pathways = read_pathway_from_json_file(os.path.join(pathway_folder,\"c2.cp.kegg.v7.5.1.json\"), gex_genes)\n",
    "kegg_pathways_with_indices = get_pathways_with_indices(kegg_pathways)\n",
    "number_of_pathways = len(kegg_pathways_with_indices)\n",
    "pathways_input_dimension = sum((len(pathway) for pathway in kegg_pathways_with_indices))\n",
    "number_of_input_genes = len(functools.reduce(lambda acc_p, p: acc_p.union(set(p)), kegg_pathways_with_indices, set()))\n",
    "number_of_pathways, pathways_input_dimension, number_of_input_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark_pathways = read_pathway_from_json_file(os.path.join(pathway_folder,\"h.all.v7.5.1.json\"), gex_genes)\n",
    "hallmark_pathways_with_indices = get_pathways_with_indices(hallmark_pathways)\n",
    "number_of_pathways = len(hallmark_pathways_with_indices)\n",
    "pathways_input_dimension = sum((len(pathway) for pathway in hallmark_pathways_with_indices))\n",
    "number_of_input_genes = len(functools.reduce(lambda acc_p, p: acc_p.union(set(p)), hallmark_pathways_with_indices, set()))\n",
    "number_of_pathways, pathways_input_dimension, number_of_input_genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensembl_fpkm_phenotype_tsv_fname = os.path.join(tcga_folder, f\"TCGA.{cancer_type}.sampleMap_{cancer_type}_clinicalMatrix\")\n",
    "phenotype = pd.read_csv(ensembl_fpkm_phenotype_tsv_fname, sep=\"\\t\", index_col=\"sampleID\")\n",
    "phenotype.index = phenotype.index.rename(\"SampleID\")\n",
    "phenotype = phenotype[[c for c in phenotype.columns if \"pam50\" in c.lower()]]\n",
    "for c in phenotype.columns:\n",
    "    print(phenotype[c].count(), phenotype[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_clf_tgt = \"PAM50Call_RNAseq\"\n",
    "phenotype_clf_tgt_meta = \"PAM50\"\n",
    "phenotype_clf_map = {\n",
    "    \"LumA\":0,\n",
    "    \"LumB\":1,\n",
    "    \"Basal\":2,\n",
    "    \"Normal\":3,\n",
    "    \"Her2\":4,\n",
    "}\n",
    "phenotype_clf_nan = {f\"{value}\":np.nan for value in [np.nan, \"not reported\", \"\"]}\n",
    "phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nan\n",
    "PHENOTYPE_CLF_COLUMN = \"subtype\"\n",
    "phenotype[PHENOTYPE_CLF_COLUMN] = phenotype[phenotype_clf_tgt].replace(phenotype_clf_nan)\n",
    "phenotype = phenotype.dropna(subset=[PHENOTYPE_CLF_COLUMN])\n",
    "phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_possible_mappings = {idx:[] for idx in phenotype.index}\n",
    "for idx in phenotype.index:\n",
    "    for v in gex[gex.index.str.startswith(idx)].index.values:\n",
    "        _possible_mappings[idx].append(v)\n",
    "_replacements = {k:sorted(v)[0] for k,v in _possible_mappings.items() if len(v)>0}\n",
    "phenotype = phenotype.rename(index=_replacements, inplace=False)\n",
    "phenotype.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_index = sorted(set(phenotype.index).intersection(gex.index))\n",
    "[(len(idx), idx[:5],) for idx in [gex.index, phenotype.index, both_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_index_meta = sorted(set(metabric_phenotype.index).intersection(gex_meta.index))\n",
    "[(len(idx), idx[:5],) for idx in [gex_meta.index, metabric_phenotype.index, both_index_meta]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gex = gex.loc[both_index]\n",
    "gex_meta = gex_meta.loc[both_index_meta]\n",
    "\n",
    "full_phenotype = phenotype\n",
    "phenotype_meta = full_phenotype_meta = metabric_phenotype\n",
    "\n",
    "phenotype = phenotype.loc[both_index,[PHENOTYPE_CLF_COLUMN,]]\n",
    "phenotype_meta = full_phenotype_meta.loc[both_index_meta,[\"PAM50\"]]\n",
    "phenotype[PHENOTYPE_CLF_COLUMN] = phenotype[PHENOTYPE_CLF_COLUMN].replace(phenotype_clf_map)\n",
    "phenotype_meta[PHENOTYPE_CLF_COLUMN] = phenotype_meta[\"PAM50\"].replace(phenotype_clf_map)\n",
    "phenotype[phenotype_clf_tgt] = full_phenotype.loc[phenotype.index,phenotype_clf_tgt]\n",
    "phenotype_meta[phenotype_clf_tgt_meta] = phenotype_meta.loc[phenotype_meta.index,phenotype_clf_tgt_meta]\n",
    "\n",
    "\n",
    "(\n",
    "    phenotype[PHENOTYPE_CLF_COLUMN].value_counts(), phenotype[PHENOTYPE_CLF_COLUMN].dtype, phenotype[PHENOTYPE_CLF_COLUMN].unique(), phenotype[PHENOTYPE_CLF_COLUMN].describe(),\n",
    "    \"\\n\",\n",
    "    phenotype_meta[PHENOTYPE_CLF_COLUMN].value_counts(), phenotype_meta[PHENOTYPE_CLF_COLUMN].dtype, phenotype_meta[PHENOTYPE_CLF_COLUMN].unique(), phenotype_meta[PHENOTYPE_CLF_COLUMN].describe(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_order = sorted(phenotype[phenotype_clf_tgt].unique())\n",
    "sns.displot(data=phenotype, y=phenotype_clf_tgt, hue=phenotype_clf_tgt, hue_order=hue_order)\n",
    "plt.show()\n",
    "sns.displot(data=phenotype_meta, y=phenotype_clf_tgt_meta, hue=phenotype_clf_tgt_meta, hue_order=hue_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all((gi==pi for gi,pi in zip(gex.index.to_list(), phenotype.index.to_list()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(all((gi==pi for gi,pi in zip(gex_meta.index.to_list(), phenotype_meta.index.to_list()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d_space(df, SpaceTransformer=sklearn.decomposition.PCA, **kwargs):\n",
    "    values = SpaceTransformer().fit_transform(df)\n",
    "    return sns.scatterplot(x=values[:,0], y=values[:,1], **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_space(gex, hue=phenotype[phenotype_clf_tgt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_space(gex, SpaceTransformer=umap.UMAP, hue=phenotype[phenotype_clf_tgt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_space(gex_meta, hue=phenotype_meta[phenotype_clf_tgt_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_space(gex_meta, SpaceTransformer=umap.UMAP, hue=phenotype_meta[phenotype_clf_tgt_meta])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_dim = gex.values.shape[1]\n",
    "gex.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 1024\n",
    "BETA_START_AND_DURATION_LIST = [(32,128)]\n",
    "DEFAULT_LR = 1e-4\n",
    "BATCH_SIZE = int(gex.values.shape[0])\n",
    "MAX_PATIENCE = 8\n",
    "DEFAULT_EARLY_STOPPING_THRESHOLD = 0.001\n",
    "EARLY_STOPPING_TEST_SIZE = 0.1\n",
    "DEFAULT_SINK = lambda x:x\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "build_early_stopping = lambda: skorch.callbacks.EarlyStopping(\n",
    "    patience = 16+MAX_PATIENCE,\n",
    "    threshold = DEFAULT_EARLY_STOPPING_THRESHOLD,\n",
    "    sink = DEFAULT_SINK\n",
    ")\n",
    "\n",
    "\n",
    "kegg_p = [torch.tensor(pathway) for pathway in kegg_pathways_with_indices]\n",
    "hmrk_p = [torch.tensor(pathway) for pathway in hallmark_pathways_with_indices]\n",
    "\n",
    "pways_keys_lst = [\"KEGG\", \"Hallmark Genes\",]\n",
    "pways_defs_lst = [kegg_p, hmrk_p,]\n",
    "\n",
    "paae_pipes = {\n",
    "    **{\n",
    "        f\"PAAE-{pathway_hidden_dims}-{hidden_and_enc_dims} ({pways_key})\": sklearn.pipeline.Pipeline(\n",
    "            [\n",
    "                (\"scale\", sklearn.preprocessing.QuantileTransformer(\n",
    "                        n_quantiles=max(*gex.values.shape, *gex_meta.values.shape,),\n",
    "                        output_distribution=\"normal\",\n",
    "                        )\n",
    "                ),\n",
    "                (\n",
    "                    \"net\", \n",
    "                    ScoredNeuralNetAutoencoder(\n",
    "                        PAAE,\n",
    "                        module__genes_dim = genes_dim,\n",
    "                        module__pathway_definitions = pways,\n",
    "                        module__pathway_hidden_dims = pathway_hidden_dims,\n",
    "                        module__hidden_dims = hidden_and_enc_dims[:-1],\n",
    "                        module__encoding_dim = hidden_and_enc_dims[-1],\n",
    "                        max_epochs = MAX_EPOCHS,\n",
    "                        lr=DEFAULT_LR,\n",
    "                        iterator_train__shuffle=True,\n",
    "                        criterion = AE_MSELoss,\n",
    "                        optimizer = torch.optim.Adam,\n",
    "                        callbacks=[\n",
    "                        ],\n",
    "                        callbacks__print_log__sink = DEFAULT_SINK,\n",
    "                        device=device,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        for pways_key, pways in zip(\n",
    "            pways_keys_lst,\n",
    "            pways_defs_lst,\n",
    "        )\n",
    "        for hidden_and_enc_dims in ([64],[128,64])\n",
    "        for pathway_hidden_dims in ([],[32],[32,16])\n",
    "    },\n",
    "}\n",
    "\n",
    "ae_pipes = {\n",
    "    **{\n",
    "        f\"AE-{hidden_and_enc_dims}\": sklearn.pipeline.Pipeline(\n",
    "            [\n",
    "                (\"scale\", sklearn.preprocessing.QuantileTransformer(\n",
    "                        n_quantiles=max(*gex.values.shape, *gex_meta.values.shape,),\n",
    "                        output_distribution=\"normal\",\n",
    "                        )\n",
    "                ),\n",
    "                (\n",
    "                    \"net\", \n",
    "                    ScoredNeuralNetAutoencoder(\n",
    "                        Autoencoder,\n",
    "                        module__input_dim = genes_dim,\n",
    "                        module__hidden_dims = hidden_and_enc_dims[:-1],\n",
    "                        module__encoding_dim = hidden_and_enc_dims[-1],\n",
    "                        max_epochs = MAX_EPOCHS,\n",
    "                        lr=DEFAULT_LR,\n",
    "                        iterator_train__shuffle=True,\n",
    "                        criterion = AE_MSELoss,\n",
    "                        optimizer = torch.optim.Adam,\n",
    "                        callbacks=[\n",
    "                        ],\n",
    "                        callbacks__print_log__sink = DEFAULT_SINK,\n",
    "                        device=device,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        for hidden_and_enc_dims in (\n",
    "                [128,64], [256,128,64], [512,256,128,64],\n",
    "                )\n",
    "    }\n",
    "}\n",
    "\n",
    "vae_pipes = {\n",
    "    **{\n",
    "        f\"VAE-{beta_schedule_type}-β{beta}-{hidden_and_enc_dims}\": sklearn.pipeline.Pipeline(\n",
    "            [\n",
    "                (\"scale\", sklearn.preprocessing.QuantileTransformer(\n",
    "                        n_quantiles=max(*gex.values.shape, *gex_meta.values.shape,),\n",
    "                        output_distribution=\"normal\",\n",
    "                        )\n",
    "                ),\n",
    "                (\n",
    "                    \"net\",\n",
    "                    ScoredNeuralNetAutoencoder(\n",
    "                        VAE,\n",
    "                        module__input_dim = genes_dim,\n",
    "                        module__hidden_dims = hidden_and_enc_dims[:-1],\n",
    "                        module__encoding_dim = hidden_and_enc_dims[-1],\n",
    "                        max_epochs = MAX_EPOCHS,\n",
    "                        lr=DEFAULT_LR,\n",
    "                        batch_size = BATCH_SIZE,\n",
    "                        iterator_train__shuffle=True,\n",
    "                        criterion = VAELoss,\n",
    "                        criterion__original_loss = nn.MSELoss(),\n",
    "                        criterion__beta_schedule = build_beta_schedule(beta_schedule_type, beta_start, beta_duration=beta_duration),\n",
    "                        criterion__beta=beta,\n",
    "                        criterion__kl_type=\"kingma\",\n",
    "                        optimizer = torch.optim.Adam,\n",
    "                        callbacks=[\n",
    "                        ],\n",
    "                        callbacks__print_log__sink = DEFAULT_SINK,\n",
    "                        device=device,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        for beta in [1,5,10,50,100]\n",
    "        for beta_start, beta_duration in BETA_START_AND_DURATION_LIST\n",
    "        for beta_schedule_type in (\"smooth\", \"step\",)\n",
    "        for hidden_and_enc_dims in ([128,64], [256,128,64], [512,256,128,64],)\n",
    "    },\n",
    "}\n",
    "\n",
    "pavae_pipes = {\n",
    "    **{\n",
    "        f\"PAVAE-{beta_schedule_type}-β{beta}-{pathway_hidden_dims}-{hidden_and_enc_dims} ({pways_key})\": sklearn.pipeline.Pipeline(\n",
    "            [\n",
    "                (\"scale\", sklearn.preprocessing.QuantileTransformer(\n",
    "                        n_quantiles=max(*gex.values.shape, *gex_meta.values.shape,),\n",
    "                        output_distribution=\"normal\",\n",
    "                        )\n",
    "                ),\n",
    "                (\n",
    "                    \"net\",\n",
    "                    ScoredNeuralNetAutoencoder(\n",
    "                        PAVAE,\n",
    "                        module__genes_dim = genes_dim,\n",
    "                        module__pathway_definitions = pways,\n",
    "                        module__pathway_hidden_dims = pathway_hidden_dims,\n",
    "                        module__hidden_dims = hidden_and_enc_dims[:-1],\n",
    "                        module__encoding_dim = hidden_and_enc_dims[-1],\n",
    "                        max_epochs = MAX_EPOCHS,\n",
    "                        lr=DEFAULT_LR,\n",
    "                        batch_size = BATCH_SIZE,\n",
    "                        iterator_train__shuffle=True,\n",
    "                        criterion = VAELoss,\n",
    "                        criterion__original_loss = nn.MSELoss(),\n",
    "                        criterion__beta_schedule = build_beta_schedule(beta_schedule_type, beta_start, beta_duration=beta_duration),\n",
    "                        criterion__beta=beta,\n",
    "                        criterion__kl_type=\"kingma\",\n",
    "                        optimizer = torch.optim.Adam,\n",
    "                        callbacks=[\n",
    "                        ],\n",
    "                        callbacks__print_log__sink = DEFAULT_SINK,\n",
    "                        device=device,\n",
    "                    )\n",
    "                ),\n",
    "            ],\n",
    "        )\n",
    "        for beta in [1,5,10,50,100]\n",
    "        for beta_start, beta_duration in BETA_START_AND_DURATION_LIST\n",
    "        for beta_schedule_type in (\"smooth\", \"step\")\n",
    "        for pways_key, pways in zip(\n",
    "            pways_keys_lst,\n",
    "            pways_defs_lst,\n",
    "        )\n",
    "        for hidden_and_enc_dims in ([128,64], [256,128,64],)\n",
    "        for pathway_hidden_dims in ([],[32],[32,16])\n",
    "    },\n",
    "}\n",
    "\n",
    "scale_pipe = sklearn.pipeline.Pipeline(\n",
    "    [\n",
    "        (\"scale\", sklearn.preprocessing.QuantileTransformer(\n",
    "                n_quantiles=max(*gex.values.shape, *gex_meta.values.shape,),\n",
    "                output_distribution=\"normal\",\n",
    "                )\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "ExperimentDefinition = collections.namedtuple(\"ModelDefinition\", [\"Model\", \"params\"])\n",
    "\n",
    "params = {\n",
    "    \"net__lr\": [DEFAULT_LR],\n",
    "    \"net__max_epochs\":  [MAX_EPOCHS],\n",
    "}\n",
    "\n",
    "models_to_test_dict = {\n",
    "    \"ae\": {**{k: ExperimentDefinition(ae_pipes[k], params) for k in ae_pipes}},\n",
    "    \"z-norm\": {\"z-norm\": ExperimentDefinition(scale_pipe, {})},\n",
    "    \"paae\": {**{k: ExperimentDefinition(paae_pipes[k], params) for k in paae_pipes}},\n",
    "    \"vae\": {**{k: ExperimentDefinition(vae_pipes[k], params) for k in vae_pipes}},\n",
    "    \"pavae\": {**{k: ExperimentDefinition(pavae_pipes[k], params) for k in pavae_pipes}},\n",
    "}\n",
    "\n",
    "\n",
    "models_to_test = {\n",
    "    **{k: ExperimentDefinition(ae_pipes[k], params) for k in ae_pipes},\n",
    "    \"z-norm\": ExperimentDefinition(scale_pipe, {}),\n",
    "    **{k: ExperimentDefinition(paae_pipes[k], params) for k in paae_pipes},\n",
    "    **{k: ExperimentDefinition(vae_pipes[k], params) for k in vae_pipes},\n",
    "    **{k: ExperimentDefinition(pavae_pipes[k], params) for k in pavae_pipes},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = \"results/metabric\"\n",
    "os.makedirs(results_folder, exist_ok=True)\n",
    "images_folder = \"images/metabric\"\n",
    "os.makedirs(images_folder, exist_ok=True)\n",
    "SAVING_FORMATS = [\"png\", \"pdf\", \"svg\"]\n",
    "for fmt in SAVING_FORMATS: os.makedirs(os.path.join(images_folder,fmt), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISABLE_TQDM = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_results_set = {\n",
    "    \"z-norm\": \"z-norm\",\n",
    "    \"AE-[128, 64]\": \"AE-[128, 64]\",\n",
    "    \"PAAE-[32]-[64] (KEGG)\": \"PAAE-[32]-[64] (KEGG)\",\n",
    "    \"PAAE-[32]-[64] (Hallmark Genes)\": \"PAAE-[32]-[64] (Hallmark Genes)\",\n",
    "    \"PAVAE-smooth-β1-[]-[128, 64] (KEGG)\": \"PAVAE-SVM-smooth-β1-[]-[128, 64] (KEGG)\",\n",
    "    \"PAVAE-step-[]-[128,64] (Hallmark Genes)\": \"PAVAE-step-[]-[128,64] (Hallmark Genes)\",\n",
    "    \"VAE-step-β1-[128, 64]\": \"VAE-step-β1-[128, 64]\",\n",
    "\n",
    "}\n",
    "paper_normtype = \"log2p1e-3_fpkm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_models_to_test = {k:v for k,v in models_to_test.items()}\n",
    "paper_models_to_test = {paper_results_set[k]:v for k,v in paper_models_to_test.items() if k in paper_results_set}\n",
    "normalization_types_to_test = [paper_normtype]\n",
    "print(normalization_types_to_test)\n",
    "len(paper_models_to_test), paper_models_to_test.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = sklearn.preprocessing.LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(phenotype[PHENOTYPE_CLF_COLUMN])\n",
    "y_test = label_encoder.transform(phenotype_meta[PHENOTYPE_CLF_COLUMN])\n",
    "\n",
    "y = y_train\n",
    "metrics = {\n",
    "    \"Accuracy\": sklearn.metrics.make_scorer(sklearn.metrics.accuracy_score,),\n",
    "    \"Precision\": sklearn.metrics.make_scorer(functools.partial(sklearn.metrics.precision_score, average=\"macro\" if len(set(y))>2 else \"binary\",),),\n",
    "    \"Recall\": sklearn.metrics.make_scorer(functools.partial(sklearn.metrics.recall_score, average=\"macro\" if len(set(y))>2 else \"binary\",),),\n",
    "    \"F1\": sklearn.metrics.make_scorer(functools.partial(sklearn.metrics.f1_score, average=\"macro\" if len(set(y))>2 else \"binary\"),),\n",
    "    \"AUC\": sklearn.metrics.make_scorer(functools.partial(sklearn.metrics.roc_auc_score, average=\"macro\" if len(set(y))>2 else None, multi_class=\"ovr\",), needs_proba=True),\n",
    "}\n",
    "\n",
    "CLASSIFIERS_TO_TEST = [sklearn.svm.SVC(probability=True), sklearn.linear_model.LogisticRegression(), sklearn.ensemble.RandomForestClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_time = datetime.datetime.now()\n",
    "\n",
    "models = {}\n",
    "models_latent_spaces_train = {}\n",
    "models_latent_spaces_test = {}\n",
    "models_pathway_spaces_train = {}\n",
    "models_pathway_spaces_test = {}\n",
    "models_fit_time = {}\n",
    "models_scores_train = {}\n",
    "models_scores_test = {}\n",
    "\n",
    "try:\n",
    "    X_train = gex.values\n",
    "    X_test = gex_meta.values\n",
    "\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    if not np.isfinite(X_train).all():\n",
    "        raise ValueError(f\"Some inputs were not finite\")\n",
    "    for model_name in tqdm(paper_models_to_test, desc=\"Model\", leave = False, disable = DISABLE_TQDM,):\n",
    "        Model:sklearn.pipeline.Pipeline = paper_models_to_test[model_name].Model\n",
    "        model_fit_start = time.time()\n",
    "        model = Model.fit(X_train)\n",
    "        models_fit_time[model_name] = time.time() - model_fit_start\n",
    "        if hasattr(model, \"score\"):\n",
    "            models_scores_train[model_name] = model.score(X_train)\n",
    "            models_scores_test[model_name] = model.score(X_test)\n",
    "        \n",
    "        z_train = X_train\n",
    "        z_test = X_test\n",
    "        print(model_name, models_fit_time[model_name])\n",
    "        print(\"X\", z_train.shape, z_test.shape)\n",
    "        for step_name, step in model.steps:\n",
    "            print(step_name, end=\" \")\n",
    "            if isinstance(step,ScoredNeuralNetAutoencoder):\n",
    "                module_param = next(step.module_.parameters())\n",
    "\n",
    "                # Get PAs first\n",
    "                if \"PA\" in model_name:\n",
    "                    with torch.no_grad():\n",
    "                        p_train = step.module_.get_pathway_activities(torch.tensor(z_train, device=module_param.device, dtype=module_param.dtype))\n",
    "                        p_test = step.module_.get_pathway_activities(torch.tensor(z_test, device=module_param.device, dtype=module_param.dtype))\n",
    "                    \n",
    "                    if isinstance(p_train, tuple):\n",
    "                        p_train = p_train[0]\n",
    "                    if isinstance(p_test, tuple):\n",
    "                        p_test = p_test[0]\n",
    "\n",
    "                    p_train = p_train.detach().cpu().numpy()\n",
    "                    p_test = p_test.detach().cpu().numpy()\n",
    "                    print(\"PA\", p_train.shape, p_test.shape)\n",
    "                \n",
    "                # Then update Zs\n",
    "                with torch.no_grad():\n",
    "                    z_train = step.module_.encode(torch.tensor(z_train, device=module_param.device, dtype=module_param.dtype))\n",
    "                    z_test = step.module_.encode(torch.tensor(z_test, device=module_param.device, dtype=module_param.dtype))\n",
    "\n",
    "                if isinstance(z_train, tuple):\n",
    "                    z_train = z_train[0]\n",
    "                if isinstance(z_test, tuple):\n",
    "                    z_test = z_test[0]\n",
    "\n",
    "                z_train = z_train.detach().cpu().numpy()\n",
    "                z_test = z_test.detach().cpu().numpy()\n",
    "\n",
    "                print(z_train.shape, z_test.shape)\n",
    "                break\n",
    "            z_train = step.transform(z_train)\n",
    "            if isinstance(step,sklearn.preprocessing.QuantileTransformer):\n",
    "                z_test = sklearn.preprocessing.quantile_transform(z_test, n_quantiles=step.n_quantiles, output_distribution=step.output_distribution)\n",
    "            else:\n",
    "                z_test = step.transform(z_test)\n",
    "            print(z_train.shape, z_test.shape)\n",
    "        models[model_name] = model\n",
    "        models_latent_spaces_train[model_name] = z_train\n",
    "        models_latent_spaces_test[model_name] = z_test\n",
    "        if \"PA\" in model_name:\n",
    "            models_pathway_spaces_train[model_name] = p_train\n",
    "            models_pathway_spaces_test[model_name] = p_test\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "models_fit_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_ordering = sorted(phenotype_meta[phenotype_clf_tgt_meta].unique())\n",
    "class_ordering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_latent_spaces_train.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_spaces_test = {\n",
    "    **{f\"Input Space\": (space, phenotype_meta[phenotype_clf_tgt_meta], \"Metabric\") for model, space in models_latent_spaces_test.items() if model.lower()==\"z-norm\"},\n",
    "    **{f\"{model} - Latent Space\": (space, phenotype_meta[phenotype_clf_tgt_meta], \"Metabric\") for model, space in models_latent_spaces_test.items() if model.lower()!=\"z-norm\"},\n",
    "    **{f\"{model} - Pathway Space\": (space, phenotype_meta[phenotype_clf_tgt_meta], \"Metabric\") for model, space in models_pathway_spaces_test.items()},\n",
    "}\n",
    "model_spaces_train = {\n",
    "    **{f\"Input Space\": (space, phenotype[phenotype_clf_tgt], \"TCGA\") for model, space in models_latent_spaces_train.items() if model.lower()==\"z-norm\"},\n",
    "    **{f\"{model} - Latent Space\": (space, phenotype[phenotype_clf_tgt], \"TCGA\") for model, space in models_latent_spaces_train.items() if model.lower()!=\"z-norm\"},\n",
    "    **{f\"{model} - Pathway Space\": (space, phenotype[phenotype_clf_tgt], \"TCGA\") for model, space in models_pathway_spaces_train.items()},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_scores = {\n",
    "    (model_name, space_name): {\n",
    "        \"silhouette_score\": sklearn.metrics.silhouette_score(z, y),\n",
    "        \"davis_bouldin_index\": sklearn.metrics.davies_bouldin_score(z, y),\n",
    "        \"calinski_harabasz_index\": sklearn.metrics.calinski_harabasz_score(z, y)\n",
    "    } for model_name, (z, y, space_name) in itertools.chain(model_spaces_train.items(), model_spaces_test.items())\n",
    "}\n",
    "\n",
    "\n",
    "clustering_scores_dict = {\n",
    "    \"Model\": [],\n",
    "    \"Dataset\": [],\n",
    "    \"Silhouette Score\": [],\n",
    "    \"Calinski-Harabasz Index\": [],\n",
    "    \"Davis-Bouldin Index\": [],\n",
    "}\n",
    "\n",
    "for (model_name, space_name), CSs in clustering_scores.items():\n",
    "    silhouette_score = clustering_scores[(model_name, space_name)][\"silhouette_score\"]\n",
    "    calinski_harabasz_index = clustering_scores[(model_name, space_name)][\"calinski_harabasz_index\"]\n",
    "    davis_bouldin_index = clustering_scores[(model_name, space_name)][\"davis_bouldin_index\"]\n",
    "    clustering_scores_dict[\"Model\"].append(model_name)\n",
    "    clustering_scores_dict[\"Dataset\"].append(space_name)\n",
    "    clustering_scores_dict[\"Silhouette Score\"].append(silhouette_score)\n",
    "    clustering_scores_dict[\"Calinski-Harabasz Index\"].append(calinski_harabasz_index)\n",
    "    clustering_scores_dict[\"Davis-Bouldin Index\"].append(davis_bouldin_index)\n",
    "\n",
    "clustering_scores_df = pd.DataFrame(clustering_scores_dict)\n",
    "clustering_scores_df.to_csv(os.path.join(results_folder,\"clustering_scores.csv\"))\n",
    "clustering_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score in [\"Silhouette Score\", \"Calinski-Harabasz Index\", \"Davis-Bouldin Index\",]:\n",
    "    sns.barplot(data=clustering_scores_df, x=score, y=\"Model\", hue=\"Dataset\")\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normtypes_to_show = None\n",
    "clusion_names_to_show = None\n",
    "plot_legend = False\n",
    "savefigs = True\n",
    "figsize_to_show = None#\"wide\"\n",
    "\n",
    "for space_transformer in [umap.UMAP, sklearn.decomposition.PCA, sklearn.manifold.TSNE]:\n",
    "    for model_name, (z, y, space_name) in itertools.chain(model_spaces_train.items(), model_spaces_test.items()):\n",
    "        silhouette_score = clustering_scores[(model_name, space_name)][\"silhouette_score\"]\n",
    "        calinski_harabasz_index = clustering_scores[(model_name, space_name)][\"calinski_harabasz_index\"]\n",
    "        davis_bouldin_index = clustering_scores[(model_name, space_name)][\"davis_bouldin_index\"]\n",
    "        pct_na = np.mean(np.isnan(z))\n",
    "        if pct_na>0:\n",
    "            continue\n",
    "        for figsizename, figsize in [\n",
    "            (\"default\",None),\n",
    "            (\"thin\",(3,5)),\n",
    "            (\"wide\",(7,5)),\n",
    "        ]:\n",
    "            plt.figure(figsize=figsize)\n",
    "            plot_2d_space(z, SpaceTransformer=umap.UMAP, hue=y, hue_order=class_ordering, alpha=0.5,)\n",
    "            plt.xticks([])\n",
    "            plt.yticks([])\n",
    "            plt.xlabel(f\"{space_transformer.__name__} 1\")\n",
    "            plt.ylabel(f\"{space_transformer.__name__} 2\")\n",
    "            plt.title(f\"{model_name} (SS={silhouette_score:.3f}, CHI={calinski_harabasz_index:.3f}, DBI={davis_bouldin_index:.3f})\")\n",
    "            \n",
    "            if not plot_legend:\n",
    "                plt.legend([],[], frameon=False)\n",
    "            if savefigs:\n",
    "                model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "                for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"brca-scatter-{figsizename}-{space_transformer.__name__}-{space_name.lower()}-{model_fname}.{fmt}\"), bbox_inches=\"tight\")\n",
    "            if figsize_to_show==figsizename and space_transformer.__name__==\"UMAP\":\n",
    "                    print(model_name, space_name, figsizename)\n",
    "                    plt.show()\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hallmark_pathway_description_path = os.path.join(pathway_folder,\"h.all.v7.5.1.json\")\n",
    "\n",
    "with open(hallmark_pathway_description_path, \"r\") as f:\n",
    "    hallmark_pathway_descriptions = json.load(f)\n",
    "hallmark_pathway_genes = [(k,hallmark_pathway_descriptions[k][\"geneSymbols\"]) for k in hallmark_pathway_descriptions]\n",
    "hallmark_all_pathway_genes = functools.reduce(lambda acc, v: acc.union(set(v[1])), hallmark_pathway_genes, set())\n",
    "hallmark_common_genes = hallmark_all_pathway_genes.intersection(gex_genes)\n",
    "hallmark_pathway_genes_with_allowed_genes = [(k,[gene for gene in pathway if gene in hallmark_common_genes]) for k, pathway in hallmark_pathway_genes]\n",
    "\n",
    "hallmark_pway_names = [k for (k,p), pi in zip(hallmark_pathway_genes_with_allowed_genes,hallmark_pathways_with_indices)]\n",
    "assert(all([(len(p)==len(pi)) for (k,p), pi in zip(hallmark_pathway_genes_with_allowed_genes,hallmark_pathways_with_indices)]))\n",
    "hallmark_pway_names = [pname.replace(\"HALLMARK_\",\"\") for pname in hallmark_pway_names]\n",
    "len(hallmark_pway_names), hallmark_pway_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_pathway_description_path = os.path.join(pathway_folder,\"c2.cp.kegg.v7.5.1.json\")\n",
    "\n",
    "with open(kegg_pathway_description_path, \"r\") as f:\n",
    "    kegg_pathway_descriptions = json.load(f)\n",
    "kegg_pathway_genes = [(k,kegg_pathway_descriptions[k][\"geneSymbols\"]) for k in kegg_pathway_descriptions]\n",
    "kegg_all_pathway_genes = functools.reduce(lambda acc, v: acc.union(set(v[1])), kegg_pathway_genes, set())\n",
    "kegg_common_genes = kegg_all_pathway_genes.intersection(gex_genes)\n",
    "kegg_pathway_genes_with_allowed_genes = [(k,[gene for gene in pathway if gene in kegg_common_genes]) for k, pathway in kegg_pathway_genes]\n",
    "\n",
    "kegg_pway_names = [k for (k,p), pi in zip(kegg_pathway_genes_with_allowed_genes,kegg_pathways_with_indices)]\n",
    "assert(all([(len(p)==len(pi)) for (k,p), pi in zip(kegg_pathway_genes_with_allowed_genes,kegg_pathways_with_indices)]))\n",
    "kegg_pway_names = [pname.replace(\"KEGG_\",\"\") for pname in kegg_pway_names]\n",
    "len(kegg_pway_names), kegg_pway_names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathway_set_to_use = \"Hallmark Genes\"\n",
    "base_model_name_to_use = \"PAAE-[32]-[64]\"\n",
    "\n",
    "pathway_set_to_use_dict = {\n",
    "    \"Hallmark Genes\": hallmark_pway_names,\n",
    "    \"KEGG\": kegg_pway_names,\n",
    "}\n",
    "\n",
    "clustermap_k_map = {\n",
    "    \"KEGG\": 32,\n",
    "    \"Hallmark Genes\": 50\n",
    "}\n",
    "\n",
    "featuremap_k_map = {\n",
    "    \"KEGG\": 32,\n",
    "    \"Hallmark Genes\": 50\n",
    "}\n",
    "\n",
    "violinplot_k_map = {\n",
    "    \"KEGG\": 32,\n",
    "    \"Hallmark Genes\": 50\n",
    "}\n",
    "\n",
    "pway_names = pathway_set_to_use_dict[pathway_set_to_use]\n",
    "base_model_name = f\"{base_model_name_to_use} ({pathway_set_to_use})\"\n",
    "base_model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_pathway_spaces_train[base_model_name].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_train = True\n",
    "if use_train:\n",
    "    pathway_space_to_use_dataset_name = \"TCGA\"\n",
    "    pathway_space_to_use = pd.DataFrame(models_pathway_spaces_train[base_model_name], index=gex.index, columns=pway_names)\n",
    "    phenotype_series_col = \"PAM50Call_RNAseq\"\n",
    "    phenotype_to_use = phenotype\n",
    "else:\n",
    "    pathway_space_to_use_dataset_name = \"Metabric\"\n",
    "    pathway_space_to_use = pd.DataFrame(models_pathway_spaces_test[base_model_name], index=gex_meta.index, columns=pway_names)\n",
    "    phenotype_series_col = \"PAM50\"\n",
    "    phenotype_to_use = phenotype_meta\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pway_df = pathway_space_to_use.copy()\n",
    "pway_scores = sorted(zip(pway_df.columns,sklearn.feature_selection.mutual_info_classif(pway_df,phenotype_to_use[phenotype_series_col])), key=lambda x:x[1], reverse=True,)\n",
    "\n",
    "model_name = f\"{base_model_name} - Pathway Space\"\n",
    "model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "\n",
    "pd.DataFrame(\n",
    "    data = {\"Pathway\": [p for p,_ in pway_scores], \"Mutual Information\": [mi for _,mi in pway_scores]}\n",
    ").set_index(\n",
    "    \"Pathway\"\n",
    ").to_csv(\n",
    "    os.path.join(results_folder,f\"brca-pathway-{pathway_space_to_use_dataset_name}-{model_fname}-mi-{results_time:%Y%m%d%H%M}.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_k_best_pathways_k = 32\n",
    "pway_df.columns[:show_k_best_pathways_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = []\n",
    "\n",
    "s_to_e = {s:e for s,e in replacements}\n",
    "e_to_s = {e:s for s,e in replacements}\n",
    "for s, e in replacements:\n",
    "    if (s_to_e[s]!=e):\n",
    "        print(f\"Start {s} has duplicate with end {e}\")\n",
    "    if (e_to_s[e]!=s):\n",
    "        print(f\"End {e} has duplicate with start {s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PWAY_NAME_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_k_best_pathways_k = clustermap_k_map[pathway_set_to_use]\n",
    "plot_df = pway_df[[p for p,s in pway_scores[:show_k_best_pathways_k]]]\n",
    "plot_df_cols = functools.reduce(lambda cols, mapping: cols.str.replace(*mapping,), replacements, plot_df.columns)\n",
    "model_name = f\"{base_model_name} - Pathway Space\"\n",
    "\n",
    "# Create a categorical palette to identify the networks\n",
    "unique_phenotypes = phenotype[phenotype_clf_tgt].unique()\n",
    "\n",
    "phenotype_pal = sns.color_palette()\n",
    "phenotype_lut = dict(zip(unique_phenotypes, phenotype_pal))\n",
    "phenotype_colors = pd.Series(phenotype_to_use[phenotype_series_col]).map(phenotype_lut)\n",
    "\n",
    "for metric in ['correlation', 'cosine', 'euclidean',]:\n",
    "    print(metric)\n",
    "    try:\n",
    "        try:\n",
    "            g = sns.clustermap(plot_df.T, cmap=\"vlag\",\n",
    "                metric=metric,\n",
    "                col_colors=phenotype_colors,\n",
    "                col_cluster=True,\n",
    "                row_cluster=True,\n",
    "            )\n",
    "        except KeyboardInterrupt:\n",
    "            raise\n",
    "        except:\n",
    "            continue\n",
    "        old_yticks = g.ax_heatmap.get_yticks()\n",
    "        old_yticklabels = g.ax_heatmap.get_yticklabels()\n",
    "        new_yticks = np.arange(min(old_yticks),min(old_yticks)+len(plot_df.columns),1)\n",
    "        g.ax_heatmap.set_yticks(new_yticks, labels = plot_df_cols[g.dendrogram_row.reordered_ind].str[:MAX_PWAY_NAME_SIZE])\n",
    "        g.ax_heatmap.set_xticklabels([])\n",
    "\n",
    "        g.ax_col_dendrogram.remove()\n",
    "        g.ax_cbar.remove()\n",
    "        plt.title(\"\")\n",
    "        model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "        for fmt in SAVING_FORMATS: g.savefig(os.path.join(images_folder,fmt,f\"clustermap-BRCA-{pathway_space_to_use_dataset_name}-{model_fname}-{metric}.{fmt}\"), dpi=600)\n",
    "        plt.close()\n",
    "    except KeyboardInterrupt:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_pal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotype_lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_k_best_pathways_k = 32\n",
    "plot_df = pway_df[[p for p,s in pway_scores[:show_k_best_pathways_k]]]\n",
    "\n",
    "# Create a categorical palette to identify the networks\n",
    "unique_phenotypes = phenotype[phenotype_clf_tgt].unique()\n",
    "phenotype_colors = pd.Series(phenotype_to_use[phenotype_series_col]).map(phenotype_lut)\n",
    "\n",
    "g = sns.clustermap(plot_df[[p for p,s in pway_scores[:show_k_best_pathways_k]]].T,\n",
    "                   col_colors=phenotype_colors,\n",
    "                   col_cluster=True,\n",
    "                   row_cluster=True,\n",
    ")\n",
    "old_yticks = g.ax_heatmap.get_yticks()\n",
    "new_yticks = np.arange(min(old_yticks),min(old_yticks)+len(plot_df.columns),1)\n",
    "g.ax_heatmap.set_yticks(new_yticks, labels = plot_df.columns[g.dendrogram_row.reordered_ind])\n",
    "g.ax_heatmap.set_xticklabels([])\n",
    "g.ax_col_dendrogram.remove()\n",
    "g.ax_cbar.remove()\n",
    "\n",
    "# Draw the full plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_pway_df = pway_df.copy()\n",
    "values_umap = umap.UMAP().fit_transform(extra_pway_df.values)\n",
    "for i in range(values_umap.shape[1]):\n",
    "    extra_pway_df[f\"UMAP {i}\"] = values_umap[:,i]\n",
    "model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "extra_pway_df.to_csv(f\"pway_and_umap_{model_fname}.csv\")\n",
    "phenotype.to_csv(f\"pheno_{model_fname}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extra_pway_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_k_best_pathways_k = 5\n",
    "save_k_best_pathways_k = featuremap_k_map[pathway_set_to_use]\n",
    "\n",
    "figsizename,figsize=(\"wide\",(7,5))\n",
    "plot_legend=True\n",
    "savefigs=True\n",
    "showfigs=[phenotype_series_col,] + [p for p,s in pway_scores[:show_k_best_pathways_k]]\n",
    "model_name = f\"{base_model_name} - Pathway Space\"\n",
    "model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "\n",
    "col_score_dict = dict(pway_scores)\n",
    "col_score_dict[phenotype_series_col] = sklearn.feature_selection.mutual_info_classif(phenotype_to_use[[\"subtype\"]],phenotype_to_use[phenotype_series_col], discrete_features=True)[0]\n",
    "\n",
    "for col in [phenotype_series_col] + [p for p,s in pway_scores[:save_k_best_pathways_k]]:\n",
    "    if col in [\"UMAP 0\",\"UMAP 1\"]: continue\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    if col == phenotype_series_col:\n",
    "        sns.scatterplot(data=extra_pway_df,x=\"UMAP 0\",y=\"UMAP 1\", hue=phenotype_to_use[phenotype_series_col], alpha=0.5,)\n",
    "    else:\n",
    "        sns.scatterplot(data=extra_pway_df,x=\"UMAP 0\",y=\"UMAP 1\", hue=col, palette=\"vlag\", alpha=0.5)\n",
    "    plt.title(f\"{model_name} [MI:{col_score_dict[col]:.4f}]\")\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.xlabel(f\"UMAP 0\")\n",
    "    plt.ylabel(f\"UMAP 1\")\n",
    "    if not plot_legend:\n",
    "        print(plt.legend())\n",
    "        plt.legend([],[], frameon=False)\n",
    "    if savefigs:\n",
    "        \n",
    "        for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"brca-{pathway_space_to_use_dataset_name}-scatter-{model_fname}-UMAP-{figsizename}-{col}.{fmt}\"), bbox_inches=\"tight\")\n",
    "    if col in showfigs:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_k_best_pathways_k = 5\n",
    "save_k_best_pathways_k = violinplot_k_map[pathway_set_to_use]\n",
    "\n",
    "figsizename,figsize=(\"wide\",(7,5))\n",
    "plot_legend=True\n",
    "savefigs=True\n",
    "showfigs=[phenotype_series_col,] + [ps[0] for ps in pway_scores[:show_k_best_pathways_k]]\n",
    "model_name = f\"{base_model_name} - Pathway Space\"\n",
    "\n",
    "col_score_dict = dict(pway_scores)\n",
    "col_score_dict[phenotype_series_col] = sklearn.feature_selection.mutual_info_classif(phenotype_to_use[[\"subtype\"]],phenotype_to_use[phenotype_series_col], discrete_features=True)[0]\n",
    "\n",
    "for col in [p for p,s in pway_scores[:save_k_best_pathways_k]]:\n",
    "    if col in [\"UMAP 0\",\"UMAP 1\"]: continue\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.violinplot(data=extra_pway_df, y=col, x=phenotype_to_use[phenotype_series_col], hue=phenotype_to_use[phenotype_series_col], dodge=False)\n",
    "    plt.title(f\"{model_name} [MI:{col_score_dict[col]:.4f}]\")\n",
    "    if not plot_legend:\n",
    "        print(plt.legend())\n",
    "        plt.legend([],[], frameon=False)\n",
    "    if savefigs:\n",
    "        model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "        for fmt in SAVING_FORMATS: plt.savefig(os.path.join(images_folder,fmt,f\"brca-{pathway_space_to_use_dataset_name}-violin-{model_fname}-UMAP-{figsizename}-{col}.{fmt}\"), bbox_inches=\"tight\")\n",
    "    if col in showfigs:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = base_model_name\n",
    "model_fname = model_name.replace('(','_').replace(')','_').replace('-','_').replace(' ','')\n",
    "torch.save(models[model_name][\"net\"].module_.state_dict(), os.path.join(results_folder,f\"{model_fname}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load(os.path.join(results_folder,f\"{model_fname}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "momics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6aa1c49e068f69db5bcdfd06143621343d5e21d0aa95c73e4e0dd023b1fedc27"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
